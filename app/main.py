"""LC-MS Analysis Web Application - Streamlit Entry Point."""

import streamlit as st

# Page configuration - must be first Streamlit command
st.set_page_config(
    page_title="LC-MS Analysis",
    page_icon=":material/science:",
    layout="centered",
    initial_sidebar_state="expanded"
)

# Minimal imports needed for loading screen
from pathlib import Path
import os

# ETH Zurich blue color
ETH_BLUE = "#215CAF"

# Loading overlay CSS/HTML
LOADING_OVERLAY = f"""
<style>
    .loading-overlay {{
        position: fixed;
        top: 0;
        left: 0;
        width: 100vw;
        height: 100vh;
        background: white;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        z-index: 999999;
    }}
    .spinner {{
        width: 60px;
        height: 60px;
        position: relative;
        animation: spinner-rotate 1.2s linear infinite;
    }}
    .spinner-dot {{
        position: absolute;
        width: 10px;
        height: 10px;
        background: {ETH_BLUE};
        border-radius: 50%;
        animation: spinner-fade 1.2s linear infinite;
    }}
    .spinner-dot:nth-child(1) {{ top: 0; left: 25px; animation-delay: 0s; }}
    .spinner-dot:nth-child(2) {{ top: 7px; left: 43px; animation-delay: -0.15s; }}
    .spinner-dot:nth-child(3) {{ top: 25px; left: 50px; animation-delay: -0.3s; }}
    .spinner-dot:nth-child(4) {{ top: 43px; left: 43px; animation-delay: -0.45s; }}
    .spinner-dot:nth-child(5) {{ top: 50px; left: 25px; animation-delay: -0.6s; }}
    .spinner-dot:nth-child(6) {{ top: 43px; left: 7px; animation-delay: -0.75s; }}
    .spinner-dot:nth-child(7) {{ top: 25px; left: 0; animation-delay: -0.9s; }}
    .spinner-dot:nth-child(8) {{ top: 7px; left: 7px; animation-delay: -1.05s; }}
    @keyframes spinner-rotate {{
        100% {{ transform: rotate(360deg); }}
    }}
    @keyframes spinner-fade {{
        0%, 100% {{ opacity: 0.2; transform: scale(0.8); }}
        50% {{ opacity: 1; transform: scale(1); }}
    }}
    .loading-text {{
        margin-top: 24px;
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        font-size: 16px;
        color: #333;
    }}
</style>
<div class="loading-overlay">
    <div class="spinner">
        <div class="spinner-dot"></div>
        <div class="spinner-dot"></div>
        <div class="spinner-dot"></div>
        <div class="spinner-dot"></div>
        <div class="spinner-dot"></div>
        <div class="spinner-dot"></div>
        <div class="spinner-dot"></div>
        <div class="spinner-dot"></div>
    </div>
    <div class="loading-text">Please wait...</div>
</div>
"""

# Show loading overlay immediately
_loading_placeholder = st.empty()
_loading_placeholder.markdown(LOADING_OVERLAY, unsafe_allow_html=True)


# Lazy load heavy modules using cache_resource
@st.cache_resource(show_spinner=False)
def _init_heavy_modules():
    """Initialize heavy modules once per process."""
    import numpy
    import matplotlib.pyplot as plt
    import matplotlib
    # Pre-configure matplotlib
    matplotlib.use('Agg')
    plt.rcParams.update({
        'font.size': 8,
        'axes.titlesize': 9,
        'axes.labelsize': 8,
        'xtick.labelsize': 7,
        'ytick.labelsize': 7,
        'legend.fontsize': 7,
        'figure.titlesize': 10
    })
    return True


# Initialize heavy modules (cached - only slow on first run)
_init_heavy_modules()

# Now import everything (will be fast since modules are already loaded)
import numpy as np
import matplotlib.pyplot as plt
import zipfile
import tempfile
import shutil

import config
from data_reader import list_d_folders_cached, read_sample_cached, check_rainbow_available
from analysis import (
    extract_eic, smooth_data, calculate_peak_area, find_peaks, find_spectrum_peaks,
    sum_spectra_in_range, deconvolute_protein, deconvolute_protein_agilent_like,
    detect_singly_charged, get_theoretical_mz
)
from plotting import (
    create_single_sample_figure,
    create_time_progression_figure,
    create_eic_comparison_figure,
    create_deconvolution_figure,
    create_deconvoluted_masses_figure,
    create_mass_spectrum_figure,
    export_figure,
    export_figure_svg,
    export_figure_pdf
)

# Clear loading overlay
_loading_placeholder.empty()

# Custom CSS
st.markdown("""
<style>
    html, body { height: 100%; overflow: auto !important; }
    body { position: relative; }
    div[data-testid="stAppViewContainer"] { height: 100%; overflow: auto !important; }
    div[data-testid="stApp"] { height: 100%; overflow: auto !important; }
    section[data-testid="stSidebar"] { overflow: auto !important; }
    .main .block-container { overflow: visible !important; }
    .stSelectbox label { font-weight: bold; }
    .main .block-container { padding-top: 2rem; }
    div[data-testid="stMetricValue"] { font-size: 1.2rem; }
    /* Reduce spacing in sidebar */
    section[data-testid="stSidebar"] .stCheckbox { margin-bottom: -10px; }
    section[data-testid="stSidebar"] .stButton { margin-bottom: -5px; }
    section[data-testid="stSidebar"] button { padding: 0.25rem 0.5rem; }
</style>
""", unsafe_allow_html=True)


def is_running_locally():
    """Check if running locally (desktop app) vs cloud."""
    # Check for Streamlit Cloud environment variables
    if os.environ.get('STREAMLIT_SHARING_MODE'):
        return False
    if os.environ.get('STREAMLIT_SERVER_HEADLESS') == 'true':
        # Could be cloud or local headless, check for common cloud indicators
        if os.environ.get('HOME', '').startswith('/home/appuser'):
            return False
    # Check if we have access to local file system
    return os.path.exists('/Users') or os.path.exists('C:\\') or os.path.exists('/home')


def init_session_state():
    """Initialize session state variables."""
    if 'selected_files' not in st.session_state:
        st.session_state.selected_files = []
    if 'loaded_samples' not in st.session_state:
        st.session_state.loaded_samples = {}
    if 'mz_targets' not in st.session_state:
        st.session_state.mz_targets = config.DEFAULT_MZ_VALUES.copy()
    if 'current_path' not in st.session_state or not os.path.exists(st.session_state.current_path):
        st.session_state.current_path = config.BASE_PATH
    if 'uploaded_files_dir' not in st.session_state:
        st.session_state.uploaded_files_dir = None
    if 'data_source' not in st.session_state:
        # Default to 'browse' for local/desktop, 'upload' for cloud
        st.session_state.data_source = 'browse' if is_running_locally() else 'upload'


def handle_file_upload(uploaded_files):
    """Handle uploaded ZIP files containing .D folders."""
    if not uploaded_files:
        return []

    extracted_paths = []

    # Create temp directory for this session if not exists
    if st.session_state.uploaded_files_dir is None or not os.path.exists(st.session_state.uploaded_files_dir):
        st.session_state.uploaded_files_dir = tempfile.mkdtemp(prefix="lcms_")

    temp_dir = st.session_state.uploaded_files_dir

    for uploaded_file in uploaded_files:
        try:
            if uploaded_file.name.endswith('.zip'):
                # Extract ZIP file
                zip_path = os.path.join(temp_dir, uploaded_file.name)
                with open(zip_path, 'wb') as f:
                    f.write(uploaded_file.getbuffer())

                # Extract contents (skip macOS metadata)
                extract_dir = os.path.join(temp_dir, uploaded_file.name.replace('.zip', ''))
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    for member in zip_ref.namelist():
                        # Skip macOS metadata files (anywhere in path)
                        basename = os.path.basename(member.rstrip('/'))
                        if (member.startswith('__MACOSX') or
                            '__MACOSX/' in member or
                            basename.startswith('._') or
                            basename == '.DS_Store'):
                            continue
                        zip_ref.extract(member, extract_dir)

                # Clean up any remaining macOS metadata
                for root, dirs, files in os.walk(extract_dir):
                    # Remove __MACOSX folders
                    if '__MACOSX' in dirs:
                        shutil.rmtree(os.path.join(root, '__MACOSX'), ignore_errors=True)
                        dirs.remove('__MACOSX')
                    # Remove ._ files and .DS_Store
                    for f in files:
                        if f.startswith('._') or f == '.DS_Store':
                            try:
                                os.remove(os.path.join(root, f))
                            except:
                                pass

                # Find .D folders in extracted contents (use set to avoid duplicates)
                found_d_folders = set()

                # Always walk through looking for .D folders inside the extracted content
                for root, dirs, files in os.walk(extract_dir):
                    for d in dirs:
                        if d.endswith('.D') or d.endswith('.d'):
                            d_path = os.path.abspath(os.path.join(root, d))
                            found_d_folders.add(d_path)
                    # Don't recurse into .D folders
                    dirs[:] = [d for d in dirs if not (d.endswith('.D') or d.endswith('.d'))]

                # If no .D folders found inside, check if extract_dir itself contains the data files
                if not found_d_folders:
                    # Check if this folder has .MS or .ch files (it might be the .D folder contents)
                    try:
                        files_in_extract = os.listdir(extract_dir)
                        has_data_files = any(f.endswith('.MS') or f.endswith('.ch') for f in files_in_extract)
                        if has_data_files:
                            found_d_folders.add(os.path.abspath(extract_dir))
                    except:
                        pass

                extracted_paths.extend(found_d_folders)

                # Clean up zip file
                os.remove(zip_path)

        except Exception as e:
            st.error(f"Error processing {uploaded_file.name}: {e}")

    return extracted_paths


def handle_folder_upload(uploaded_files):
    """Handle uploaded files from folder selection (webkitdirectory)."""
    if not uploaded_files:
        return []

    extracted_paths = []

    # Create temp directory for this session if not exists
    if st.session_state.uploaded_files_dir is None or not os.path.exists(st.session_state.uploaded_files_dir):
        st.session_state.uploaded_files_dir = tempfile.mkdtemp(prefix="lcms_")

    temp_dir = st.session_state.uploaded_files_dir

    # Group files by their .D folder
    d_folders = {}
    for uploaded_file in uploaded_files:
        # File path like "FolderName.D/subfolder/file.ext" or "FolderName.D/file.ext"
        file_path = uploaded_file.name

        # Skip macOS metadata
        if '/__MACOSX/' in file_path or file_path.startswith('__MACOSX'):
            continue
        basename = os.path.basename(file_path)
        if basename.startswith('._') or basename == '.DS_Store':
            continue

        # Find the .D folder in the path
        parts = file_path.replace('\\', '/').split('/')
        d_folder_name = None
        d_folder_idx = -1
        for i, part in enumerate(parts):
            if part.endswith('.D') or part.endswith('.d'):
                d_folder_name = part
                d_folder_idx = i
                break

        if d_folder_name:
            if d_folder_name not in d_folders:
                d_folders[d_folder_name] = []
            # Get relative path within .D folder
            rel_path = '/'.join(parts[d_folder_idx:])
            d_folders[d_folder_name].append((rel_path, uploaded_file))

    # Write files to temp directory
    for d_folder_name, files in d_folders.items():
        d_folder_path = os.path.join(temp_dir, d_folder_name)

        for rel_path, uploaded_file in files:
            file_full_path = os.path.join(temp_dir, rel_path)
            os.makedirs(os.path.dirname(file_full_path), exist_ok=True)

            with open(file_full_path, 'wb') as f:
                f.write(uploaded_file.getbuffer())

        if os.path.isdir(d_folder_path):
            extracted_paths.append(os.path.abspath(d_folder_path))

    return extracted_paths


def sidebar_file_upload():
    """Render file upload interface in sidebar."""
    st.sidebar.header("Upload Data")

    # Upload method selector
    upload_method = st.sidebar.radio(
        "Upload method",
        ["ZIP file", "Folder (direct)"],
        horizontal=True,
        help="ZIP works everywhere. Folder upload works in Chrome/Edge/Firefox."
    )

    if upload_method == "ZIP file":
        st.sidebar.markdown("Upload your `.D` folder as a ZIP file")

        uploaded_files = st.sidebar.file_uploader(
            "Upload .D folder (as ZIP)",
            type=['zip'],
            accept_multiple_files=True,
            key="file_uploader_zip"
        )

        if uploaded_files:
            new_paths = handle_file_upload(uploaded_files)
            for path in new_paths:
                if path not in st.session_state.selected_files:
                    st.session_state.selected_files.append(path)

    else:
        st.sidebar.markdown("""
        **Steps:**
        1. Click 'Browse files' below
        2. Navigate INTO your .D folder
        3. Select ALL files (Ctrl+A / Cmd+A)
        4. Click Open
        """)

        uploaded_files = st.sidebar.file_uploader(
            "Select all files from .D folder",
            accept_multiple_files=True,
            key="file_uploader_folder"
        )

        if uploaded_files:
            new_paths = handle_folder_upload(uploaded_files)
            for path in new_paths:
                if path not in st.session_state.selected_files:
                    st.session_state.selected_files.append(path)

            if new_paths:
                st.sidebar.success(f"Found {len(new_paths)} .D folder(s)")

    # Show debug info for selected files
    if st.session_state.selected_files:
        with st.sidebar.expander("Extracted files (debug)"):
            for d_path in st.session_state.selected_files:
                st.caption(f"**{Path(d_path).name}**")
                st.text(f"Path: {d_path}")
                try:
                    files = list(Path(d_path).iterdir())
                    file_names = [f.name for f in files if f.is_file()]
                    st.text(f"Files ({len(file_names)}): {', '.join(file_names[:20])}")
                    has_ms = any(f.endswith('.MS') for f in file_names)
                    has_uv = any(f.endswith('.ch') for f in file_names)
                    st.text(f"MS: {'Yes' if has_ms else 'No'}, UV: {'Yes' if has_uv else 'No'}")
                except Exception as e:
                    st.text(f"Error listing: {e}")

    # Show uploaded/selected files
    if st.session_state.selected_files:
        st.sidebar.subheader(f"Selected Files ({len(st.session_state.selected_files)})")

        for path in st.session_state.selected_files:
            col1, col2 = st.sidebar.columns([4, 1])
            with col1:
                st.caption(Path(path).name)
            with col2:
                if st.button("X", key=f"remove_upload_{path}"):
                    st.session_state.selected_files.remove(path)
                    if path in st.session_state.loaded_samples:
                        del st.session_state.loaded_samples[path]
                    st.rerun()

        if st.sidebar.button("Clear all uploads"):
            st.session_state.selected_files = []
            st.session_state.loaded_samples = {}
            # Clean up temp directory
            if st.session_state.uploaded_files_dir and os.path.exists(st.session_state.uploaded_files_dir):
                shutil.rmtree(st.session_state.uploaded_files_dir, ignore_errors=True)
                st.session_state.uploaded_files_dir = None
            st.rerun()

    return st.session_state.selected_files


def get_folder_contents(path: str) -> tuple[list[dict], list[dict]]:
    """Get subfolders and .D folders in a directory."""
    subfolders = []
    d_folders = []

    try:
        p = Path(path)
        for item in p.iterdir():
            try:
                name = item.name
                # Skip hidden files/folders
                if name.startswith('.'):
                    continue

                if item.is_dir():
                    if name.endswith('.D') or name.endswith('.d'):
                        # This is a .D data folder
                        try:
                            stat = item.stat()
                            d_folders.append({
                                'path': str(item),
                                'name': name,
                                'date': stat.st_mtime,
                            })
                        except (OSError, PermissionError):
                            pass
                    else:
                        # Regular subfolder
                        subfolders.append({
                            'path': str(item),
                            'name': name
                        })
            except (OSError, PermissionError):
                # Skip files/folders we can't access
                continue
    except (OSError, PermissionError) as e:
        st.sidebar.error(f"Cannot access folder: {e}")

    # Sort results
    subfolders.sort(key=lambda x: x['name'].lower())
    d_folders.sort(key=lambda x: x['name'].lower())

    return subfolders, d_folders


def extract_apex_spectrum(sample, start_time: float, end_time: float, n_scans: int = 1):
    """
    Extract spectrum around TIC apex within the time window.

    Args:
        sample: SampleData object
        start_time: Start of time window (minutes)
        end_time: End of time window (minutes)
        n_scans: Number of scans to average around apex (1 = single scan, 3-5 recommended)

    Returns:
        Tuple of (mz_array, intensity_array)
    """
    if sample.ms_scans is None or sample.ms_times is None:
        return np.array([]), np.array([])

    time_mask = (sample.ms_times >= start_time) & (sample.ms_times <= end_time)
    scan_indices = np.where(time_mask)[0]
    if len(scan_indices) == 0:
        return np.array([]), np.array([])

    # Find apex scan (highest TIC)
    apex_idx = None
    max_sum = -1.0
    for idx in scan_indices:
        scan = sample.ms_scans[idx]
        if scan is None:
            continue
        total = float(np.sum(scan)) if isinstance(scan, np.ndarray) else 0.0
        if total > max_sum:
            max_sum = total
            apex_idx = idx

    if apex_idx is None:
        return np.array([]), np.array([])

    # If n_scans == 1, return single apex scan (original behavior)
    if n_scans <= 1:
        if sample.ms_mz_axis is not None:
            return sample.ms_mz_axis, sample.ms_scans[apex_idx]
        return sum_spectra_in_range(sample, start_time, end_time)

    # Otherwise, average n_scans centered on apex
    half = n_scans // 2

    # Find valid range within time window
    apex_pos = np.where(scan_indices == apex_idx)[0][0]
    start_pos = max(0, apex_pos - half)
    end_pos = min(len(scan_indices) - 1, apex_pos + half)

    # Get the actual scan indices to average
    scans_to_avg = scan_indices[start_pos:end_pos + 1]

    if len(scans_to_avg) == 0:
        return np.array([]), np.array([])

    # Average the scans
    if sample.ms_mz_axis is not None:
        mz_axis = sample.ms_mz_axis
        summed_intensities = np.zeros(len(mz_axis))
        count = 0
        for idx in scans_to_avg:
            scan = sample.ms_scans[idx]
            if scan is not None and isinstance(scan, np.ndarray):
                summed_intensities += scan
                count += 1
        if count > 0:
            summed_intensities /= count  # Average, not sum
        return mz_axis, summed_intensities

    # Fallback: use sum_spectra_in_range for the apex window
    apex_start_time = float(sample.ms_times[scans_to_avg[0]])
    apex_end_time = float(sample.ms_times[scans_to_avg[-1]])
    mz, intensity = sum_spectra_in_range(sample, apex_start_time, apex_end_time)
    # Normalize to average
    if len(scans_to_avg) > 1:
        intensity = intensity / len(scans_to_avg)
    return mz, intensity


def render_text_table(rows: list[dict], columns: list[str], max_lines: int = 0) -> None:
    """Render a simple ASCII table to avoid pyarrow dependency.

    Args:
        rows: List of row dictionaries
        columns: Column names
        max_lines: If > 0, show scrollable container with this many visible lines
    """
    if not rows:
        st.info("No results to display.")
        return
    col_widths = []
    for col in columns:
        max_len = len(col)
        for row in rows:
            max_len = max(max_len, len(str(row.get(col, ""))))
        col_widths.append(max_len)

    def fmt_row(vals):
        return " | ".join(str(v).ljust(w) for v, w in zip(vals, col_widths))

    header = fmt_row(columns)
    sep = "-+-".join("-" * w for w in col_widths)
    lines = [header, sep]
    for row in rows:
        lines.append(fmt_row([row.get(col, "") for col in columns]))

    if max_lines > 0 and len(rows) > max_lines:
        # Calculate height: ~1.4em per line, plus header and separator
        height_px = int((max_lines + 2) * 22)  # ~22px per line in code block
        st.markdown(
            f'<div style="max-height: {height_px}px; overflow-y: auto;">'
            f'<pre style="margin: 0; padding: 0.5em; background: #262730; color: #fafafa; '
            f'border-radius: 0.25rem; font-size: 14px;">{chr(10).join(lines)}</pre></div>',
            unsafe_allow_html=True
        )
    else:
        st.code("\n".join(lines), language="text")


def get_windows_drives() -> list[str]:
    """Return a list of available Windows drive roots (e.g., C:\\, D:\\)."""
    if os.name != "nt":
        return []
    drives: list[str] = []
    for letter in "CDEFGHIJKLMNOPQRSTUVWXYZ":
        drive = f"{letter}:\\"
        if os.path.exists(drive):
            drives.append(drive)
    return drives


def sidebar_file_browser():
    """Render the interactive file browser in the sidebar."""

    current_path = st.session_state.current_path

    # File browser in collapsible expander
    with st.sidebar.expander("File Browser", expanded=len(st.session_state.selected_files) == 0):
        # Path input + Go button
        path_col, go_col = st.columns([4, 1])
        with path_col:
            new_path = st.text_input(
                "Current Path",
                value=current_path,
                key="path_display",
            )
        with go_col:
            if st.button("Go", use_container_width=True):
                if new_path and Path(new_path).exists():
                    st.session_state.current_path = new_path
                    st.rerun()
                else:
                    st.warning(f"Path not found: {new_path}")

        # Quick drive buttons on Windows
        drives = get_windows_drives()
        if drives:
            st.caption("Drives")
            drive_cols = st.columns(min(len(drives), 4))
            for i, drive in enumerate(drives):
                with drive_cols[i % len(drive_cols)]:
                    if st.button(drive, key=f"drive_{drive}", use_container_width=True):
                        st.session_state.current_path = drive
                        st.rerun()

        # Navigation buttons
        col1, col2 = st.columns(2)
        with col1:
            if st.button("↑ Up", use_container_width=True):
                parent = str(Path(current_path).parent)
                st.session_state.current_path = parent
                st.rerun()
        with col2:
            if st.button("⌂ Home", use_container_width=True):
                st.session_state.current_path = config.BASE_PATH
                st.rerun()

        # Check if path exists
        if not Path(current_path).exists():
            st.warning(f"Path not found: {current_path}")
            st.info("Make sure the network drive is mounted.")
            return []

        # Get contents
        subfolders, d_folders = get_folder_contents(current_path)

        # Show subfolders as clickable buttons
        if subfolders:
            st.caption("Folders")
            for folder in subfolders:
                if st.button(f"{folder['name']}", key=f"folder_{folder['path']}", use_container_width=True):
                    st.session_state.current_path = folder['path']
                    st.rerun()

        # Show .D folders for selection
        if d_folders:
            st.caption(f"Data Files ({len(d_folders)})")

            # Sort options
            col1, col2 = st.columns(2)
            with col1:
                sort_by = st.selectbox("Sort by", ["Date (Newest)", "Date (Oldest)", "Name (A-Z)", "Name (Z-A)"], key="sort_option")

            if sort_by == "Name (A-Z)":
                d_folders.sort(key=lambda x: x['name'].lower())
            elif sort_by == "Name (Z-A)":
                d_folders.sort(key=lambda x: x['name'].lower(), reverse=True)
            elif sort_by == "Date (Newest)":
                d_folders.sort(key=lambda x: x['date'], reverse=True)
            elif sort_by == "Date (Oldest)":
                d_folders.sort(key=lambda x: x['date'])

            # Checkbox for each .D folder
            for d_folder in d_folders:
                is_selected = d_folder['path'] in st.session_state.selected_files
                if st.checkbox(
                    f"{d_folder['name']}",
                    value=is_selected,
                    key=f"select_{d_folder['path']}"
                ):
                    if d_folder['path'] not in st.session_state.selected_files:
                        st.session_state.selected_files.append(d_folder['path'])
                else:
                    if d_folder['path'] in st.session_state.selected_files:
                        st.session_state.selected_files.remove(d_folder['path'])

        if not subfolders and not d_folders:
            st.info("No folders or .D files found here")

    # Show selected files summary in expander
    if st.session_state.selected_files:
        with st.sidebar.expander(f"Selected Files ({len(st.session_state.selected_files)})", expanded=True):
            for path in st.session_state.selected_files:
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.caption(Path(path).name)
                with col2:
                    if st.button("X", key=f"remove_{path}"):
                        st.session_state.selected_files.remove(path)
                        st.rerun()

            if st.button("Clear all", use_container_width=True):
                st.session_state.selected_files = []
                st.rerun()

    return st.session_state.selected_files


def sidebar_settings():
    """Render settings in sidebar."""
    st.sidebar.header("Settings")

    # Graph/Export settings (collapsible, at top)
    with st.sidebar.expander("Graph & Export Settings"):
        # DPI
        export_dpi = st.slider(
            "Export DPI",
            min_value=72,
            max_value=600,
            value=config.EXPORT_DPI,
            step=50,
            help="Resolution for PNG export"
        )

        # Figure dimensions
        fig_width = st.slider(
            "Figure width (inches)",
            min_value=4,
            max_value=16,
            value=6,
            step=1
        )
        fig_height_per_panel = st.slider(
            "Height per panel (inches)",
            min_value=1,
            max_value=5,
            value=2,
            step=1
        )

        # Line settings
        line_width = st.slider(
            "Line width",
            min_value=0.5,
            max_value=3.0,
            value=0.8,
            step=0.1
        )

        # Grid
        show_grid = st.checkbox("Show grid", value=False)

        st.caption("Time progression colors:")
        col1, col2, col3 = st.columns(3)
        with col1:
            color_initial = st.color_picker("Initial", config.TIME_COLORS["initial"])
        with col2:
            color_mid = st.color_picker("Mid", config.TIME_COLORS["mid"])
        with col3:
            color_final = st.color_picker("Final", config.TIME_COLORS["final"])

    # Labels & Titles settings
    with st.sidebar.expander("Labels & Titles"):
        # Main titles
        title_single = st.text_input("Single sample title", value="Sample: {name}", help="Use {name} for sample name")
        title_progression = st.text_input("Time progression title", value="Time Progression Analysis")

        # Axis labels
        x_label = st.text_input("X-axis label", value="Time (min)")

        st.caption("Y-axis labels:")
        y_label_uv = st.text_input("UV Y-axis", value="UV {wavelength}nm (mAU)", help="Use {wavelength} for wavelength value")
        y_label_tic = st.text_input("TIC Y-axis", value="TIC Intensity")
        y_label_eic = st.text_input("EIC Y-axis", value="EIC Intensity")

        st.caption("Panel titles:")
        panel_title_uv = st.text_input("UV panel", value="UV Chromatogram ({wavelength} nm)")
        panel_title_tic = st.text_input("TIC panel", value="Total Ion Chromatogram (TIC)")
        panel_title_eic = st.text_input("EIC panel", value="EIC m/z {mz} (±{window})", help="Use {mz} and {window}")

    # Ionization mode
    ion_mode = st.sidebar.radio(
        "Ionization Mode",
        ["Positive (+)", "Negative (-)"],
        horizontal=True,
        help="Select MS ionization mode"
    )

    # UV wavelength - show checkboxes based on available wavelengths
    st.sidebar.markdown("**UV Wavelengths**")

    # Get available wavelengths from loaded samples
    available_wavelengths = set()
    for sample in st.session_state.loaded_samples.values():
        if hasattr(sample, 'uv_wavelengths') and sample.uv_wavelengths is not None:
            for wl in sample.uv_wavelengths:
                try:
                    available_wavelengths.add(float(wl))
                except (ValueError, TypeError):
                    pass

    # Initialize selected wavelengths in session state
    if 'selected_wavelengths' not in st.session_state:
        st.session_state.selected_wavelengths = []

    selected_wavelengths = []
    if available_wavelengths:
        sorted_wls = sorted(available_wavelengths)
        for wl in sorted_wls:
            # Default: select 194nm if available, otherwise first wavelength
            default_selected = (wl == 194.0) or (wl == sorted_wls[0] and 194.0 not in available_wavelengths)
            if st.sidebar.checkbox(f"{wl:.0f} nm", value=default_selected, key=f"uv_wl_{wl}"):
                selected_wavelengths.append(wl)
    else:
        st.sidebar.caption("Load a sample to see available wavelengths")
        selected_wavelengths = [config.UV_WAVELENGTH]  # fallback

    # Use first selected or default
    uv_wl = selected_wavelengths[0] if selected_wavelengths else config.UV_WAVELENGTH

    # m/z window
    mz_window = st.sidebar.slider(
        "m/z window (±)",
        min_value=0.1,
        max_value=2.0,
        value=config.DEFAULT_MZ_WINDOW,
        step=0.1
    )

    # Smoothing settings
    with st.sidebar.expander("Smoothing"):
        uv_smooth = st.slider(
            "UV smoothing",
            min_value=1,
            max_value=99,
            value=config.UV_SMOOTHING_WINDOW,
            step=2
        )
        eic_smooth = st.slider(
            "EIC smoothing",
            min_value=1,
            max_value=49,
            value=config.EIC_SMOOTHING_WINDOW,
            step=2
        )

    # m/z targets in sidebar
    with st.sidebar.expander("Target m/z Values", expanded=True):
        # Quick add
        new_mz = st.number_input(
            "Add m/z",
            min_value=0.0,
            max_value=2000.0,
            value=100.0,
            step=0.01,
            key="new_mz_input"
        )
        if st.button("+ Add", key="add_mz_btn"):
            if new_mz not in st.session_state.mz_targets:
                st.session_state.mz_targets.append(new_mz)
                st.rerun()

        # Show current targets
        st.caption("Current targets:")
        for i, mz in enumerate(st.session_state.mz_targets):
            col1, col2 = st.columns([3, 1])
            with col1:
                st.write(f"m/z {mz:.2f}")
            with col2:
                if st.button("X", key=f"rm_mz_{i}"):
                    st.session_state.mz_targets.pop(i)
                    st.rerun()

        if st.button("Reset to defaults"):
            st.session_state.mz_targets = config.DEFAULT_MZ_VALUES.copy()
            st.rerun()

    return {
        'uv_wavelength': uv_wl,
        'uv_wavelengths': selected_wavelengths,  # all selected wavelengths
        'uv_smoothing': uv_smooth,
        'eic_smoothing': eic_smooth,
        'mz_window': mz_window,
        'ion_mode': 'positive' if 'Positive' in ion_mode else 'negative',
        'export_dpi': export_dpi,
        'fig_width': fig_width,
        'fig_height_per_panel': fig_height_per_panel,
        'line_width': line_width,
        'show_grid': show_grid,
        'y_scale': 'linear',
        'colors': {
            'initial': color_initial,
            'mid': color_mid,
            'final': color_final
        },
        'labels': {
            'title_single': title_single,
            'title_progression': title_progression,
            'x_label': x_label,
            'y_label_uv': y_label_uv,
            'y_label_tic': y_label_tic,
            'y_label_eic': y_label_eic,
            'panel_title_uv': panel_title_uv,
            'panel_title_tic': panel_title_tic,
            'panel_title_eic': panel_title_eic
        }
    }


def load_samples(file_paths: list[str]) -> dict:
    """Load selected samples."""
    samples = {}
    for path in file_paths:
        if path not in st.session_state.loaded_samples:
            with st.spinner(f"Loading {Path(path).name}..."):
                sample = read_sample_cached(path)
                st.session_state.loaded_samples[path] = sample
        samples[path] = st.session_state.loaded_samples[path]
    return samples


def single_sample_analysis(sample, settings):
    """Display single sample analysis view."""
    st.header(f"Single Sample: {sample.name}")

    if sample.error:
        st.error(f"Error loading sample: {sample.error}")
        # Show debug info even on error
        with st.expander("Debug Info"):
            st.write(f"Path: {sample.folder_path}")
            if hasattr(sample, '_debug_info'):
                st.json(sample._debug_info)
        return

    # Sample info
    col1, col2, col3 = st.columns(3)
    with col1:
        has_uv = sample.uv_data is not None
        st.metric("UV Data", "Available" if has_uv else "Not found")
    with col2:
        has_ms = sample.ms_scans is not None
        st.metric("MS Data", "Available" if has_ms else "Not found")
    with col3:
        if sample.ms_times is not None:
            st.metric("MS Scans", len(sample.ms_times))

    # Generate figures in two columns
    st.divider()
    mz_targets = st.session_state.mz_targets
    style = {
        'fig_width': settings['fig_width'],
        'fig_height_per_panel': settings['fig_height_per_panel'],
        'line_width': settings['line_width'],
        'show_grid': settings['show_grid'],
        'y_scale': settings['y_scale'],
        'colors': settings['colors'],
        'labels': settings['labels']
    }

    # Two column layout for plots
    left_col, right_col = st.columns(2)

    with left_col:
        # UV Chromatograms - one panel per selected wavelength
        if sample.uv_data is not None:
            selected_wavelengths = settings.get('uv_wavelengths') or [settings['uv_wavelength']]
            for wl in selected_wavelengths:
                fig_uv, ax_uv = plt.subplots(figsize=(5, 2.5))
                uv_data = sample.get_uv_at_wavelength(wl)
                if uv_data is not None:
                    plot_data = smooth_data(uv_data, settings['uv_smoothing'])
                    ax_uv.plot(sample.uv_times, plot_data, linewidth=settings['line_width'])
                    ax_uv.set_xlabel("Time (min)", fontsize=8)
                    ax_uv.set_ylabel(f"UV {wl:.0f}nm (mAU)", fontsize=8)
                    ax_uv.set_title(f"UV Chromatogram ({wl:.0f} nm)", fontsize=9)
                    ax_uv.tick_params(labelsize=7)
                else:
                    ax_uv.text(0.5, 0.5, f"No UV data at {wl:.0f} nm", ha='center', va='center', transform=ax_uv.transAxes)
                fig_uv.tight_layout()
                st.pyplot(fig_uv, use_container_width=True)
                plt.close(fig_uv)

        # TIC
        if sample.tic is not None and sample.ms_times is not None:
            fig_tic, ax_tic = plt.subplots(figsize=(5, 2.5))
            ax_tic.plot(sample.ms_times, sample.tic, linewidth=settings['line_width'])
            ax_tic.set_xlabel("Time (min)", fontsize=8)
            ax_tic.set_ylabel("TIC Intensity", fontsize=8)
            ax_tic.set_title("Total Ion Chromatogram (TIC)", fontsize=9)
            ax_tic.tick_params(labelsize=7)
            fig_tic.tight_layout()
            st.pyplot(fig_tic, use_container_width=True)
            plt.close(fig_tic)

    with right_col:
        # EICs
        if mz_targets and sample.ms_scans is not None:
            for mz in mz_targets:
                fig_eic, ax_eic = plt.subplots(figsize=(5, 2.5))
                eic = extract_eic(sample, mz, settings['mz_window'])
                if eic is not None:
                    plot_data = smooth_data(eic, settings['eic_smoothing'])
                    ax_eic.plot(sample.ms_times, plot_data, linewidth=settings['line_width'])
                    ax_eic.set_xlabel("Time (min)", fontsize=8)
                    ax_eic.set_ylabel("EIC Intensity", fontsize=8)
                    ax_eic.set_title(f"EIC m/z {mz:.2f} (±{settings['mz_window']})", fontsize=9)
                    ax_eic.tick_params(labelsize=7)
                    ax_eic.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))
                else:
                    ax_eic.text(0.5, 0.5, f"No data for m/z {mz}", ha='center', va='center', transform=ax_eic.transAxes)
                fig_eic.tight_layout()
                st.pyplot(fig_eic, use_container_width=True)
                plt.close(fig_eic)

    # Combined figure for export
    selected_wavelengths = settings.get('uv_wavelengths') or [settings['uv_wavelength']]
    fig = create_single_sample_figure(
        sample,
        uv_wavelengths=selected_wavelengths,
        eic_targets=mz_targets,
        style=style,
        mz_window=settings['mz_window'],
        uv_smoothing=settings['uv_smoothing'],
        eic_smoothing=settings['eic_smoothing']
    )

    # Export buttons
    st.divider()
    col1, col2, col3 = st.columns(3)
    with col1:
        png_data = export_figure(fig, dpi=settings['export_dpi'])
        st.download_button(
            label="Download PNG (combined)",
            data=png_data,
            file_name=f"{sample.name}_analysis.png",
            mime="image/png"
        )
    with col2:
        svg_data = export_figure_svg(fig)
        st.download_button(
            label="Download SVG",
            data=svg_data,
            file_name=f"{sample.name}_analysis.svg",
            mime="image/svg+xml"
        )
    with col3:
        pdf_data = export_figure_pdf(fig, dpi=settings['export_dpi'])
        st.download_button(
            label="Download PDF",
            data=pdf_data,
            file_name=f"{sample.name}_analysis.pdf",
            mime="application/pdf"
        )
    plt.close(fig)

    # Show debug info at bottom
    with st.expander("Data Debug Info"):
        if hasattr(sample, '_debug_info') and sample._debug_info:
            st.json(sample._debug_info)

        # Show available wavelengths
        if sample.uv_wavelengths is not None:
            try:
                wl_list = [float(w) for w in sample.uv_wavelengths]
                st.write(f"UV wavelengths: {', '.join([f'{w:.0f}' for w in wl_list[:20]])}")
            except:
                st.write(f"UV wavelengths (raw): {list(sample.uv_wavelengths[:10])}")

        # Show MS scan info
        if sample.ms_scans is not None and len(sample.ms_scans) > 0:
            scan = sample.ms_scans[0]
            if scan is not None:
                st.write(f"First scan type: {type(scan).__name__}")
                if hasattr(scan, 'mz'):
                    st.write(f"  Has 'mz' attr: {len(scan.mz)} values, range: {min(scan.mz):.1f} - {max(scan.mz):.1f}")
                if hasattr(scan, 'masses'):
                    st.write(f"  Has 'masses' attr: {len(scan.masses)} values")
                if hasattr(scan, 'intensity'):
                    st.write(f"  Has 'intensity' attr: {len(scan.intensity)} values")
                if hasattr(scan, 'intensities'):
                    st.write(f"  Has 'intensities' attr: {len(scan.intensities)} values")
                if isinstance(scan, np.ndarray):
                    st.write(f"  Array shape: {scan.shape}")


def time_progression_analysis(samples: list, settings):
    """Display time progression comparison view."""
    st.header("Time Progression Analysis")

    if len(samples) < 2:
        st.warning("Select at least 2 samples for time progression analysis")
        return

    if len(samples) > 3:
        st.warning("Maximum 3 samples supported. Using first 3.")
        samples = samples[:3]

    # Check for errors
    for sample in samples:
        if sample.error:
            st.error(f"Error loading {sample.name}: {sample.error}")
            return

    # Label inputs
    st.subheader("Sample Labels")
    labels = []
    default_labels = ["Initial (t=0)", "Mid timepoint", "Final/Overnight"]
    cols = st.columns(len(samples))
    for i, (col, sample) in enumerate(zip(cols, samples)):
        with col:
            label = st.text_input(
                f"Label for {sample.name}",
                value=default_labels[i] if i < len(default_labels) else f"Sample {i+1}",
                key=f"label_{i}"
            )
            labels.append(label)

    # Generate figure
    st.divider()
    mz_targets = st.session_state.mz_targets
    style = {
        'fig_width': settings['fig_width'],
        'fig_height_per_panel': settings['fig_height_per_panel'],
        'line_width': settings['line_width'],
        'show_grid': settings['show_grid'],
        'y_scale': settings['y_scale'],
        'colors': settings['colors'],
        'labels': settings['labels']
    }
    fig = create_time_progression_figure(
        samples,
        labels,
        uv_wavelength=settings['uv_wavelength'],
        eic_targets=mz_targets,
        style=style,
        mz_window=settings['mz_window'],
        uv_smoothing=settings['uv_smoothing'],
        eic_smoothing=settings['eic_smoothing']
    )

    # Display
    st.pyplot(fig, use_container_width=True)

    # Export buttons
    col1, col2, col3 = st.columns(3)
    with col1:
        png_data = export_figure(fig, dpi=settings['export_dpi'])
        st.download_button(
            label="Download PNG",
            data=png_data,
            file_name="time_progression_analysis.png",
            mime="image/png"
        )
    with col2:
        svg_data = export_figure_svg(fig)
        st.download_button(
            label="Download SVG",
            data=svg_data,
            file_name="time_progression_analysis.svg",
            mime="image/svg+xml"
        )
    with col3:
        pdf_data = export_figure_pdf(fig, dpi=settings['export_dpi'])
        st.download_button(
            label="Download PDF",
            data=pdf_data,
            file_name="time_progression_analysis.pdf",
            mime="application/pdf"
        )


def eic_batch_analysis(sample, settings):
    """Display EIC batch extraction view."""
    st.header(f"EIC Batch Analysis: {sample.name}")

    if sample.error:
        st.error(f"Error loading sample: {sample.error}")
        return

    if sample.ms_scans is None:
        st.warning("No MS data available for this sample")
        return

    mz_targets = st.session_state.mz_targets

    # Display options
    col1, col2 = st.columns(2)
    with col1:
        overlay = st.checkbox("Overlay EICs", value=True)
    with col2:
        normalize = st.checkbox("Normalize", value=True)

    # Generate figure
    st.divider()
    fig = create_eic_comparison_figure(
        sample,
        mz_targets,
        mz_window=settings['mz_window'],
        smoothing=settings['eic_smoothing'],
        overlay=overlay
    )

    st.pyplot(fig, use_container_width=True)

    # Peak areas table
    st.subheader("Peak Areas")
    peak_data = []
    for mz in mz_targets:
        eic = extract_eic(sample, mz, settings['mz_window'])
        if eic is not None and sample.ms_times is not None:
            smoothed = smooth_data(eic, settings['eic_smoothing'])
            total_area = calculate_peak_area(sample.ms_times, smoothed)
            peaks = find_peaks(sample.ms_times, smoothed)
            main_peak_time = peaks[0]['time'] if peaks else None
            main_peak_area = peaks[0]['area'] if peaks else None

            peak_data.append({
                'm/z': f"{mz:.2f}",
                'Total Area': f"{total_area:.2e}",
                'Main Peak Time': f"{main_peak_time:.2f} min" if main_peak_time else "N/A",
                'Main Peak Area': f"{main_peak_area:.2e}" if main_peak_area else "N/A"
            })

    if peak_data:
        render_text_table(peak_data, list(peak_data[0].keys()) if peak_data else [])

    # Export buttons
    col1, col2, col3 = st.columns(3)
    with col1:
        png_data = export_figure(fig, dpi=settings['export_dpi'])
        st.download_button(
            label="Download PNG",
            data=png_data,
            file_name=f"{sample.name}_eic_batch.png",
            mime="image/png"
        )
    with col2:
        svg_data = export_figure_svg(fig)
        st.download_button(
            label="Download SVG",
            data=svg_data,
            file_name=f"{sample.name}_eic_batch.svg",
            mime="image/svg+xml"
        )
    with col3:
        pdf_data = export_figure_pdf(fig, dpi=settings['export_dpi'])
        st.download_button(
            label="Download PDF",
            data=pdf_data,
            file_name=f"{sample.name}_eic_batch.pdf",
            mime="application/pdf"
        )


def deconvolution_analysis(sample, settings):
    """Display protein deconvolution analysis view."""
    import matplotlib.pyplot as plt

    st.header(f"Protein Deconvolution: {sample.name}")

    if sample.error:
        st.error(f"Error loading sample: {sample.error}")
        return

    if sample.ms_scans is None or sample.ms_times is None:
        st.warning("No MS data available for this sample")
        return

    # Time range selection
    st.subheader("Select Time Region")

    min_time = float(sample.ms_times[0])
    max_time = float(sample.ms_times[-1])

    # Track which sample we're working with - reset values if sample changed
    if 'deconv_current_sample' not in st.session_state:
        st.session_state.deconv_current_sample = None
    if 'deconv_widget_key' not in st.session_state:
        st.session_state.deconv_widget_key = 0

    sample_changed = st.session_state.deconv_current_sample != sample.name
    if sample_changed:
        st.session_state.deconv_current_sample = sample.name
        st.session_state.deconv_widget_key += 1  # Force widget recreation
        # Reset time values to be re-initialized with auto-detect
        if 'deconv_start_val' in st.session_state:
            del st.session_state.deconv_start_val
        if 'deconv_end_val' in st.session_state:
            del st.session_state.deconv_end_val
        # Clear previous deconvolution output for the old sample
        if 'deconv_results' in st.session_state:
            del st.session_state.deconv_results
        if 'deconv_auto_profile_note' in st.session_state:
            del st.session_state.deconv_auto_profile_note
        if 'deconv_last_run_sig' in st.session_state:
            del st.session_state.deconv_last_run_sig

    # Auto-detect main peak
    if 'deconv_auto_start' not in st.session_state or sample_changed:
        st.session_state.deconv_auto_start = None
        st.session_state.deconv_auto_end = None
        st.session_state.deconv_autorun_pending = False
        st.session_state.deconv_last_autorun_sig = None

    if sample.tic is not None:
        # Find the main peak in TIC
        from analysis import find_peaks
        tic_smoothed = smooth_data(sample.tic, 5)
        peaks = find_peaks(sample.ms_times, tic_smoothed, height_threshold=0.3, prominence=0.1)

        if peaks:
            # For C4 methods, skip the early injection/void peak (~<1.8 min)
            # which contains salts and buffer components, not protein.
            is_c4 = getattr(sample, 'is_c4_method', False)
            if is_c4:
                protein_peaks = [p for p in peaks if p['time'] >= 1.8]
                if protein_peaks:
                    peaks = protein_peaks

            # Find envelope of ALL significant peaks (>10% of max intensity)
            # so multi-component samples get a wide enough time range.
            max_peak_int = max(p['intensity'] for p in peaks)
            sig_peaks = [p for p in peaks if p['intensity'] >= max_peak_int * 0.10]
            if not sig_peaks:
                sig_peaks = [max(peaks, key=lambda p: p['intensity'])]

            # Use the outermost significant peaks to define boundaries
            first_peak = min(sig_peaks, key=lambda p: p['time'])
            last_peak = max(sig_peaks, key=lambda p: p['time'])

            # Expand left from earliest peak to 30% of its height
            threshold_left = first_peak['intensity'] * 0.3
            left_idx = first_peak['index']
            while left_idx > 0 and tic_smoothed[left_idx] > threshold_left:
                left_idx -= 1

            # Expand right from latest peak to 30% of its height
            threshold_right = last_peak['intensity'] * 0.3
            right_idx = last_peak['index']
            while right_idx < len(tic_smoothed) - 1 and tic_smoothed[right_idx] > threshold_right:
                right_idx += 1

            auto_start = float(sample.ms_times[left_idx])
            auto_end = float(sample.ms_times[right_idx])

            st.session_state.deconv_auto_start = auto_start
            st.session_state.deconv_auto_end = auto_end

    # Initialize time values in session state - use auto-detected values if available
    if 'deconv_start_val' not in st.session_state:
        if st.session_state.deconv_auto_start is not None:
            st.session_state.deconv_start_val = st.session_state.deconv_auto_start
            st.session_state.deconv_autorun_pending = True
        else:
            st.session_state.deconv_start_val = min_time
    if 'deconv_end_val' not in st.session_state:
        if st.session_state.deconv_auto_end is not None:
            st.session_state.deconv_end_val = st.session_state.deconv_auto_end
            st.session_state.deconv_autorun_pending = True
        else:
            st.session_state.deconv_end_val = min(min_time + 1.0, max_time)

    # Auto-detect button
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        auto_detect_clicked = st.button("Auto-detect main peak", type="secondary")
    with col2:
        if st.session_state.deconv_auto_start is not None:
            st.caption(f"Detected: {st.session_state.deconv_auto_start:.2f} - {st.session_state.deconv_auto_end:.2f} min")

    # Apply auto-detect values if button was clicked
    if auto_detect_clicked and st.session_state.deconv_auto_start is not None:
        st.session_state.deconv_start_val = st.session_state.deconv_auto_start
        st.session_state.deconv_end_val = st.session_state.deconv_auto_end
        st.session_state.deconv_widget_key += 1  # Force widget recreation
        st.session_state.deconv_autorun_pending = True
        st.rerun()

    # Helper to parse time input (accepts comma or period as decimal)
    def parse_time(text, default, min_val, max_val):
        try:
            # Replace comma with period for European format
            val = float(text.replace(',', '.'))
            return max(min_val, min(max_val, val))
        except (ValueError, AttributeError):
            return default

    # Format time without trailing zeros
    def format_time(val):
        formatted = f"{val:.3f}".rstrip('0').rstrip('.')
        return formatted if formatted else "0"

    # Text inputs for time (accepts comma as decimal separator)
    widget_key = st.session_state.deconv_widget_key
    col1, col2 = st.columns(2)
    with col1:
        start_text = st.text_input(
            "Start time (min)",
            value=format_time(st.session_state.deconv_start_val),
            key=f"deconv_start_{widget_key}"
        )
        start_time = parse_time(start_text, st.session_state.deconv_start_val, min_time, max_time)
    with col2:
        end_text = st.text_input(
            "End time (min)",
            value=format_time(st.session_state.deconv_end_val),
            key=f"deconv_end_{widget_key}"
        )
        end_time = parse_time(end_text, st.session_state.deconv_end_val, min_time, max_time)

    # Update session state from parsed values
    st.session_state.deconv_start_val = start_time
    st.session_state.deconv_end_val = end_time

    # Show TIC with region selector
    if sample.tic is not None:
        fig_tic, ax = plt.subplots(figsize=(12, 3))
        ax.plot(sample.ms_times, sample.tic, 'b-', linewidth=0.8)
        ax.axvspan(start_time, end_time, alpha=0.3, color='yellow', label='Selected region')
        ax.set_xlabel("Time (min)")
        ax.set_ylabel("TIC Intensity")
        ax.set_title("TIC - Select region (adjust times above)")
        ax.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))
        ax.legend()
        ax.grid(True, alpha=0.3)
        st.pyplot(fig_tic, use_container_width=True)
        plt.close(fig_tic)

    # Spectrum extraction — default to Average (sum) for best Agilent agreement
    extraction_mode = "Average (sum)"
    apex_n_scans = 1

    # Always show mass spectrum for selected region
    st.subheader(f"Mass Spectrum ({format_time(start_time)} - {format_time(end_time)} min)")

    if extraction_mode == "Peak apex":
        mz, intensity = extract_apex_spectrum(sample, start_time, end_time, n_scans=apex_n_scans)
    else:
        mz, intensity = sum_spectra_in_range(sample, start_time, end_time)

    if len(mz) > 0:
        # m/z range filter (dynamic keys to update when time range changes)
        range_key = f"{start_time:.3f}_{end_time:.3f}"
        col1, col2 = st.columns(2)
        with col1:
            mz_min_display = st.number_input("Display m/z min", value=float(mz[0]), step=10.0, key=f"mz_min_{range_key}")
        with col2:
            mz_max_display = st.number_input("Display m/z max", value=float(mz[-1]), step=10.0, key=f"mz_max_{range_key}")

        # Filter for display
        display_mask = (mz >= mz_min_display) & (mz <= mz_max_display)
        mz_display = mz[display_mask]
        intensity_display = intensity[display_mask]

        # Find peaks for labeling (use centroiding for accurate m/z)
        peaks = find_spectrum_peaks(mz_display, intensity_display, height_threshold=0.05, min_distance=3, use_centroid=True)
        top_peaks = peaks[:15]  # Label top 15 peaks

        # Plot mass spectrum
        fig_ms, ax = plt.subplots(figsize=(14, 5))
        ax.plot(mz_display, intensity_display, 'b-', linewidth=0.8)

        # Add peak labels (whole numbers since data is ~1 Da resolution)
        for peak in top_peaks:
            ax.annotate(
                f"{peak['mz']:.0f}",
                xy=(peak['mz'], peak['intensity']),
                xytext=(0, 5),
                textcoords='offset points',
                ha='center',
                fontsize=7,
                rotation=90
            )

        ax.set_xlabel("m/z")
        ax.set_ylabel("Intensity")
        ax.set_title(f"Summed Mass Spectrum ({format_time(start_time)} - {format_time(end_time)} min)")
        ax.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))
        ax.grid(True, alpha=0.3)
        ax.set_xlim(mz_min_display, mz_max_display)
        # Add headroom for labels (20% extra at top)
        y_max = intensity_display.max() if len(intensity_display) > 0 else 1
        ax.set_ylim(0, y_max * 1.2)
        plt.tight_layout()
        st.pyplot(fig_ms, use_container_width=True)

        # Export buttons for summed mass spectrum
        col1, col2, col3 = st.columns(3)
        with col1:
            png_data = export_figure(fig_ms, dpi=settings['export_dpi'])
            st.download_button(
                label="Download PNG",
                data=png_data,
                file_name=f"{sample.name}_mass_spectrum.png",
                mime="image/png",
                key="ms_png"
            )
        with col2:
            svg_data = export_figure_svg(fig_ms)
            st.download_button(
                label="Download SVG",
                data=svg_data,
                file_name=f"{sample.name}_mass_spectrum.svg",
                mime="image/svg+xml",
                key="ms_svg"
            )
        with col3:
            pdf_data = export_figure_pdf(fig_ms, dpi=settings['export_dpi'])
            st.download_button(
                label="Download PDF",
                data=pdf_data,
                file_name=f"{sample.name}_mass_spectrum.pdf",
                mime="application/pdf",
                key="ms_pdf"
            )
        plt.close(fig_ms)

        # Store spectrum in session state for deconvolution
        st.session_state.deconv_mz = mz
        st.session_state.deconv_intensity = intensity
        st.session_state.deconv_time_range = (start_time, end_time)
    else:
        st.warning("No mass spectrum data found in selected region")
        return

    st.divider()

    # Deconvolution parameters
    st.subheader("Deconvolution")

    # Deconvolution method — default to Agilent-like for best accuracy
    method = "Agilent-like"

    # Defaults for Agilent-like parameters - matched to Agilent's actual defaults
    # From PDF: MW Agreement 0.05%, Noise 1000, Abundance 10%, MW Assign 40%, Envelope 50%
    pwhh = 0.6
    mw_agreement_pct = 0.05           # Agilent default: 0.05%
    noise_cutoff = 1000.0             # Agilent default: 1000 counts
    abundance_cutoff_pct = 10.0       # Agilent default: 10%
    mw_assign_cutoff_pct = 40.0       # Agilent default: 40%
    envelope_cutoff_pct = 50.0        # Agilent default: 50%
    contig_min = 3
    use_mz_agreement = False
    use_monoisotopic = False
    include_singly_charged = False
    min_peaks = 3
    max_peaks = 50
    mass_tolerance = 1.0
    low_mw = 500
    high_mw = 50000
    min_charge = 5
    max_charge = 50

    # Display settings (outside expander for easy access)
    top_n_masses = st.slider("Show top N masses", min_value=1, max_value=20, value=5, key="top_n_masses")

    with st.expander("Deconvolution Parameters", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            low_mw = st.number_input("Low MW (Da)", min_value=100, max_value=500000, value=500, step=100)
        with col2:
            high_mw = st.number_input("High MW (Da)", min_value=100, max_value=500000, value=50000, step=1000)

        col1, col2, col3 = st.columns(3)
        with col1:
            min_charge = st.number_input("Min charge", min_value=1, max_value=100, value=5)
        with col2:
            max_charge = st.number_input("Max charge", min_value=1, max_value=100, value=50)
        with col3:
            noise_cutoff = st.number_input("Noise cutoff (counts)", min_value=0.0, max_value=1e9, value=1000.0, step=100.0,
                                           help="Agilent default: 1000")
        include_singly_charged = st.checkbox(
            "Include singly-charged (z=1) ions",
            value=False,
            help="Off by default to keep protein deconvolution ranking focused on charge envelopes."
        )

        # Expert mode — hidden by default
        expert_mode = st.checkbox("Expert mode", value=False, key="deconv_expert_mode")

        if expert_mode:
            st.caption("Method & extraction")
            col1, col2, col3 = st.columns(3)
            with col1:
                method = st.selectbox(
                    "Deconvolution method",
                    ["Agilent-like", "Simple"],
                    index=0,
                    key="deconv_method"
                )
            with col2:
                extraction_mode = st.selectbox(
                    "Spectrum extraction",
                    ["Average (sum)", "Peak apex"],
                    index=0,
                    key="deconv_spectrum_mode"
                )
            with col3:
                if extraction_mode == "Peak apex":
                    apex_n_scans = st.selectbox(
                        "Apex window",
                        [1, 3, 5, 7],
                        index=1,
                        format_func=lambda x: f"{x} scan{'s' if x > 1 else ''}",
                        key="apex_n_scans",
                        help="Number of scans to average around the TIC apex."
                    )

            st.caption("Advanced parameters")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                min_peaks = st.number_input("Min peaks in set", min_value=2, max_value=50, value=3)
            with col2:
                max_peaks = st.number_input("Max peaks in set", min_value=2, max_value=100, value=50)
            with col3:
                mass_tolerance = st.number_input("Mass tolerance (Da)", min_value=0.1, max_value=100.0, value=1.0, step=0.1)
            with col4:
                pwhh = st.number_input("Ion PWHH (Da)", min_value=0.05, max_value=5.0, value=0.6, step=0.05)

            if method == "Agilent-like":
                col1, col2, col3 = st.columns(3)
                with col1:
                    mw_agreement_pct = st.number_input("MW agreement (%)", min_value=0.001, max_value=5.0, value=0.05, step=0.01,
                                                       help="Agilent default: 0.05%")
                with col2:
                    abundance_cutoff_pct = st.number_input("Abundance cutoff (%)", min_value=0.0, max_value=100.0, value=10.0, step=1.0,
                                                           help="Agilent default: 10%")
                with col3:
                    mw_assign_cutoff_pct = st.number_input("MW assign cutoff (%)", min_value=0.0, max_value=100.0, value=40.0, step=1.0,
                                                           help="Agilent default: 40%")

                col1, col2, col3 = st.columns(3)
                with col1:
                    envelope_cutoff_pct = st.number_input("Envelope cutoff (%)", min_value=0.0, max_value=100.0, value=50.0, step=1.0,
                                                          help="Agilent default: 50%")
                with col2:
                    contig_min = st.number_input("Min contiguous charges", min_value=1, max_value=50, value=3, step=1)
                with col3:
                    use_mz_agreement = st.checkbox("Use m/z agreement", value=False)

                use_monoisotopic = st.checkbox(
                    "Monoisotopic H+",
                    value=False,
                    help="Use monoisotopic proton mass (1.007276) instead of average (1.00784). Try toggling if masses are ~1-2 Da off."
                )

    def _longest_contiguous_run(charges):
        """Return longest run of consecutive charge states."""
        if not charges:
            return 0
        charge_list = sorted(set(int(c) for c in charges))
        longest = 1
        current = 1
        for i in range(1, len(charge_list)):
            if charge_list[i] == charge_list[i - 1] + 1:
                current += 1
                longest = max(longest, current)
            else:
                current = 1
        return longest

    def _is_trustworthy_protein_component(result):
        """Heuristic: protein envelopes should have many contiguous charges."""
        charge_states = result.get('charge_states', [])
        num_charges = len(set(charge_states))
        if num_charges < 8:
            return False
        longest = _longest_contiguous_run(charge_states)
        return longest >= 6 and (longest / num_charges) >= 0.60

    def _needs_low_mw_profile(primary_results):
        """
        Decide whether to switch from default protein profile to low-MW profile.

        If no strong, trustworthy protein envelope appears in top results, run a
        low-MW fallback profile (charges 2-8).
        """
        if not primary_results:
            return True

        ranked = sorted(primary_results, key=lambda x: x.get('intensity', 0.0), reverse=True)
        top = ranked[:3]
        top_intensity = float(top[0].get('intensity', 0.0)) if top else 0.0
        if top_intensity <= 0:
            return True

        for result in top:
            rel_intensity = float(result.get('intensity', 0.0)) / top_intensity
            if rel_intensity >= 0.25 and _is_trustworthy_protein_component(result):
                return False
        return True

    def run_deconvolution():
        with st.spinner("Running deconvolution..."):
            auto_profile_note = None
            if method == "Agilent-like":
                results = deconvolute_protein_agilent_like(
                    mz, intensity,
                    min_charge=min_charge,
                    max_charge=max_charge,
                    min_peaks=min_peaks,
                    noise_cutoff=noise_cutoff,
                    abundance_cutoff=abundance_cutoff_pct / 100.0,
                    mw_agreement=mw_agreement_pct / 100.0,
                    mw_assign_cutoff=mw_assign_cutoff_pct / 100.0,
                    envelope_cutoff=envelope_cutoff_pct / 100.0,
                    pwhh=pwhh,
                    low_mw=low_mw,
                    high_mw=high_mw,
                    contig_min=contig_min,
                    use_mz_agreement=use_mz_agreement,
                    use_monoisotopic_proton=use_monoisotopic
                )

                auto_profile_note = "Profile: Protein (auto)"

                # Default mode fallback for low-MW datasets (e.g., 3-5 kDa species).
                # Keep expert mode unchanged so manual tuning remains explicit.
                if not expert_mode and _needs_low_mw_profile(results):
                    low_profile_min = max(float(low_mw), 2000.0)
                    low_profile_max = min(float(high_mw), 10000.0)
                    if low_profile_min < low_profile_max:
                        low_results = deconvolute_protein_agilent_like(
                            mz, intensity,
                            min_charge=2,
                            max_charge=8,
                            min_peaks=max(3, int(min_peaks)),
                            noise_cutoff=noise_cutoff,
                            abundance_cutoff=min(abundance_cutoff_pct / 100.0, 0.05),
                            mw_agreement=mw_agreement_pct / 100.0,
                            mw_assign_cutoff=mw_assign_cutoff_pct / 100.0,
                            envelope_cutoff=envelope_cutoff_pct / 100.0,
                            pwhh=pwhh,
                            low_mw=low_profile_min,
                            high_mw=low_profile_max,
                            contig_min=2,
                            use_mz_agreement=use_mz_agreement,
                            use_monoisotopic_proton=use_monoisotopic
                        )
                        if low_results:
                            results = low_results
                            auto_profile_note = "Profile: Low MW (auto fallback)"
            else:
                results = deconvolute_protein(
                    mz, intensity,
                    min_charge=min_charge,
                    max_charge=max_charge,
                    mass_tolerance=mass_tolerance,
                    min_peaks=min_peaks,
                    max_peaks=max_peaks
                )

            results = [r for r in results if low_mw <= r['mass'] <= high_mw]

            # Optional merge of singly-charged (z=1) species.
            if method == "Agilent-like" and include_singly_charged:
                singly = detect_singly_charged(
                    mz, intensity,
                    noise_cutoff=noise_cutoff,
                    min_intensity_pct=abundance_cutoff_pct,
                    low_mw=low_mw,
                    high_mw=min(high_mw, 2000.0),
                    pwhh=pwhh,
                    use_monoisotopic_proton=use_monoisotopic,
                )
                results.extend(singly)

            # Sort all results by intensity descending
            results.sort(key=lambda x: x['intensity'], reverse=True)

            st.session_state.deconv_results = results
            st.session_state.deconv_mw_range = (low_mw, high_mw)
            st.session_state.deconv_use_monoisotopic = use_monoisotopic
            st.session_state.deconv_auto_profile_note = auto_profile_note
            # Mark results as fresh for current time range/parameters.
            st.session_state.deconv_last_run_sig = autorun_sig

    autorun_sig = (
        config.APP_VERSION,
        sample.name,
        round(start_time, 4),
        round(end_time, 4),
        extraction_mode,
        apex_n_scans if extraction_mode == "Peak apex" else 1,
        method,
        low_mw,
        high_mw,
        min_charge,
        max_charge,
        min_peaks,
        max_peaks,
        mass_tolerance,
        # Agilent-like params
        pwhh if method == "Agilent-like" else None,
        mw_agreement_pct if method == "Agilent-like" else None,
        noise_cutoff if method == "Agilent-like" else None,
        abundance_cutoff_pct if method == "Agilent-like" else None,
        mw_assign_cutoff_pct if method == "Agilent-like" else None,
        envelope_cutoff_pct if method == "Agilent-like" else None,
        contig_min if method == "Agilent-like" else None,
        use_mz_agreement if method == "Agilent-like" else None,
        use_monoisotopic if method == "Agilent-like" else None,
        include_singly_charged if method == "Agilent-like" else None
    )
    if st.session_state.get('deconv_autorun_pending') and st.session_state.get('deconv_last_autorun_sig') != autorun_sig:
        run_deconvolution()
        st.session_state.deconv_last_autorun_sig = autorun_sig
        st.session_state.deconv_autorun_pending = False

    # Run deconvolution button
    if st.button("Run Deconvolution", type="primary"):
        run_deconvolution()

    results_are_current = st.session_state.get('deconv_last_run_sig') == autorun_sig
    if hasattr(st.session_state, 'deconv_results') and st.session_state.deconv_results and not results_are_current:
        st.info("Time range or parameters changed. Click Run Deconvolution to refresh results.")

    # Display results if available
    if hasattr(st.session_state, 'deconv_results') and st.session_state.deconv_results and results_are_current:
        results = st.session_state.deconv_results
        mz = st.session_state.deconv_mz
        intensity = st.session_state.deconv_intensity
        time_range = st.session_state.deconv_time_range

        # Build info caption
        caption_parts = []
        auto_profile_note = st.session_state.get('deconv_auto_profile_note')
        if auto_profile_note and not expert_mode:
            caption_parts.append(auto_profile_note)
        if expert_mode:
            caption_parts.append(f"Method: {method}")
            apex_info = f" ({apex_n_scans} scans)" if extraction_mode == "Peak apex" else ""
            caption_parts.append(f"Spectrum: {extraction_mode}{apex_info}")
            if method == "Agilent-like" and use_monoisotopic:
                caption_parts.append("H+=1.007276 (mono)")
            if method == "Agilent-like" and include_singly_charged:
                caption_parts.append("z=1 included")
        if caption_parts:
            st.caption(" | ".join(caption_parts))

        show_full_precision = st.checkbox("Show full precision masses", value=False, key="deconv_full_precision")

        st.divider()
        st.subheader(f"Results ({len(results)} masses detected)")

        # Limit results to top N
        display_results = results[:top_n_masses]

        # Results table
        result_data = []
        for i, r in enumerate(display_results):
            mass_val = r['mass'] if show_full_precision else f"{r['mass']:.2f}"
            std_val = r['mass_std'] if show_full_precision else f"{r['mass_std']:.2f}"
            result_data.append({
                'Rank': i + 1,
                'Mass (Da)': mass_val,
                'Std Dev': std_val,
                'Charge States': f"{min(r['charge_states'])}-{max(r['charge_states'])}",
                'Num Charges': r['num_charges'],
                'Rel. Intensity': f"{r['intensity'] / results[0]['intensity'] * 100:.1f}%"
            })

        render_text_table(result_data, list(result_data[0].keys()) if result_data else [])

        # Create figure
        style = {
            'fig_width': settings['fig_width'],
            'line_width': settings['line_width'],
            'show_grid': settings['show_grid'],
            'top_n_masses': top_n_masses
        }

        fig = create_deconvolution_figure(sample, time_range[0], time_range[1], display_results, style)
        st.pyplot(fig, use_container_width=True)

        # Export buttons for 3-panel figure (placed directly under the graph)
        col1, col2, col3 = st.columns(3)
        with col1:
            png_data = export_figure(fig, dpi=settings['export_dpi'])
            st.download_button(
                label="Download PNG",
                data=png_data,
                file_name=f"{sample.name}_deconvolution.png",
                mime="image/png"
            )
        with col2:
            svg_data = export_figure_svg(fig)
            st.download_button(
                label="Download SVG",
                data=svg_data,
                file_name=f"{sample.name}_deconvolution.svg",
                mime="image/svg+xml"
            )
        with col3:
            pdf_data = export_figure_pdf(fig, dpi=settings['export_dpi'])
            st.download_button(
                label="Download PDF",
                data=pdf_data,
                file_name=f"{sample.name}_deconvolution.pdf",
                mime="application/pdf"
            )

        # Standalone deconvoluted masses panel (same figure size as the 3-panel plot)
        st.subheader("Deconvoluted Masses (Standalone)")
        fig_deconv_only = create_deconvoluted_masses_figure(sample.name, display_results, style)
        st.pyplot(fig_deconv_only, use_container_width=True)

        export_key_base = sample.name.replace(" ", "_").replace(".", "_")
        col1, col2, col3 = st.columns(3)
        with col1:
            png_data_only = export_figure(fig_deconv_only, dpi=settings['export_dpi'])
            st.download_button(
                label="Download PNG (deconvoluted)",
                data=png_data_only,
                file_name=f"{sample.name}_deconvoluted_masses.png",
                mime="image/png",
                key=f"deconv_only_png_{export_key_base}"
            )
        with col2:
            svg_data_only = export_figure_svg(fig_deconv_only)
            st.download_button(
                label="Download SVG (deconvoluted)",
                data=svg_data_only,
                file_name=f"{sample.name}_deconvoluted_masses.svg",
                mime="image/svg+xml",
                key=f"deconv_only_svg_{export_key_base}"
            )
        with col3:
            pdf_data_only = export_figure_pdf(fig_deconv_only, dpi=settings['export_dpi'])
            st.download_button(
                label="Download PDF (deconvoluted)",
                data=pdf_data_only,
                file_name=f"{sample.name}_deconvoluted_masses.pdf",
                mime="application/pdf",
                key=f"deconv_only_pdf_{export_key_base}"
            )

        # Show theoretical m/z for selected mass
        st.subheader("Theoretical m/z Values")
        selected_mass_idx = st.selectbox(
            "Select mass to view theoretical peaks",
            range(len(results[:10])),
            format_func=lambda i: f"{results[i]['mass']:.2f} Da",
            key="theo_mz_mass_select"
        )

        if selected_mass_idx is not None:
            selected_result = results[selected_mass_idx]
            use_mono = st.session_state.get('deconv_use_monoisotopic', False)
            theoretical = get_theoretical_mz(
                selected_result['mass'],
                selected_result['charge_states'],
                use_monoisotopic_proton=use_mono
            )

            theo_data = []
            for t in theoretical:
                theo_data.append({
                    'Charge': f"+{t['charge']}",
                    'm/z': f"{t['mz']:.4f}"
                })
            render_text_table(theo_data, list(theo_data[0].keys()) if theo_data else [], max_lines=5)

    elif hasattr(st.session_state, 'deconv_results') and results_are_current:
        st.info("No protein masses detected. Try adjusting the parameters or selecting a different time region.")


def main():
    """Main application entry point."""
    init_session_state()

    st.title("LC-MS Analysis")
    st.caption(f"Version {config.APP_VERSION}")

    # Check rainbow availability
    if not check_rainbow_available():
        st.error("rainbow-api is not installed. Please install it with: pip install rainbow-api")
        return

    # Data source selector in sidebar
    st.sidebar.header("Data Source")
    data_source = st.sidebar.radio(
        "Select data source:",
        ["Upload Files", "Browse Local"],
        index=0 if st.session_state.data_source == 'upload' else 1,
        horizontal=True
    )
    st.session_state.data_source = 'upload' if data_source == "Upload Files" else 'browse'

    # Sidebar - file selection based on mode
    if st.session_state.data_source == 'upload':
        selected_files = sidebar_file_upload()
    else:
        selected_files = sidebar_file_browser()

    # Load samples BEFORE settings so wavelengths can be detected
    if selected_files:
        load_samples(selected_files)

    settings = sidebar_settings()

    # Main content
    if not selected_files:
        if st.session_state.data_source == 'upload':
            st.info("Upload .D folder(s) as ZIP files using the sidebar to begin analysis.")
            st.markdown("""
            ### How to Upload
            1. **ZIP your .D folder** - Right-click on your `.D` folder and compress/zip it
            2. **Upload** - Use the file uploader in the sidebar
            3. **Analyze** - Select samples and view results

            ### Features
            - **Single Sample Analysis**: View UV, TIC, and EIC chromatograms
            - **Time Progression**: Compare 2-3 samples across timepoints
            - **EIC Batch Extraction**: Extract multiple EICs with peak area calculation
            - **Protein Deconvolution**: Deconvolute multiply-charged protein spectra
            - **Export**: Download plots as PNG, SVG, or PDF
            """)
        else:
            st.info("Select one or more .D folders from the sidebar to begin analysis.")
            st.markdown("""
            ### Features
            - **Single Sample Analysis**: View UV, TIC, and EIC chromatograms
            - **Time Progression**: Compare 2-3 samples across timepoints
            - **EIC Batch Extraction**: Extract multiple EICs with peak area calculation
            - **Protein Deconvolution**: Deconvolute multiply-charged protein spectra
            - **Export**: Download plots as PNG, SVG, or PDF
            """)
        return

    # Load samples
    samples = load_samples(selected_files)
    sample_list = [samples[p] for p in selected_files]

    # Initialize active tab in session state
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = "Single Sample"

    # Auto-switch to Deconvolution tab for C4 method samples
    if len(sample_list) == 1 and getattr(sample_list[0], 'is_c4_method', False):
        # Only auto-switch once per sample (not on every rerun)
        current_sample_name = sample_list[0].name
        if st.session_state.get('_c4_auto_switched') != current_sample_name:
            st.session_state.active_tab = "Deconvolution"
            st.session_state._c4_auto_switched = current_sample_name

    # Tab selector using radio buttons (preserves state across reruns)
    tab_options = ["Single Sample", "EIC Batch", "Deconvolution", "Time Progression"]
    active_tab = st.radio(
        "Analysis",
        tab_options,
        index=tab_options.index(st.session_state.active_tab) if st.session_state.active_tab in tab_options else 0,
        horizontal=True,
        key="tab_selector",
        label_visibility="collapsed"
    )
    st.session_state.active_tab = active_tab

    st.divider()

    if active_tab == "Single Sample":
        if len(selected_files) == 1:
            single_sample_analysis(sample_list[0], settings)
        else:
            sample_names = [s.name for s in sample_list]
            selected_name = st.selectbox("Select sample", sample_names, key="single_sample_select")
            selected_idx = sample_names.index(selected_name)
            single_sample_analysis(sample_list[selected_idx], settings)

    elif active_tab == "EIC Batch":
        if len(selected_files) == 1:
            eic_batch_analysis(sample_list[0], settings)
        else:
            sample_names = [s.name for s in sample_list]
            selected_name = st.selectbox("Select sample for EIC", sample_names, key="eic_sample")
            selected_idx = sample_names.index(selected_name)
            eic_batch_analysis(sample_list[selected_idx], settings)

    elif active_tab == "Deconvolution":
        if len(selected_files) == 1:
            deconvolution_analysis(sample_list[0], settings)
        else:
            sample_names = [s.name for s in sample_list]
            selected_name = st.selectbox("Select sample for Deconvolution", sample_names, key="deconv_sample")
            selected_idx = sample_names.index(selected_name)
            deconvolution_analysis(sample_list[selected_idx], settings)

    elif active_tab == "Time Progression":
        if len(selected_files) == 1:
            st.info("Select multiple samples to enable Time Progression analysis.")
        else:
            time_progression_analysis(sample_list, settings)


if __name__ == "__main__":
    main()
